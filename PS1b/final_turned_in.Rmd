---
title: "ARE 213 Problem Set 1b"
author: "Nick Depsky, Will Gorman, Peter Worley"
date: "October 12, 2018"
output:
  pdf_document: default
  html_notebook: default
---

```{r, include = F}
rm(list = ls())
library(pacman)
p_load("foreign","dplyr","magrittr","knitr","ggplot2", "corrplot", "stargazer", "glmnet","splines")
theme_plot <- theme(
  legend.position = "right",
  panel.background = element_rect(fill = NA),
  panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey85"),
  panel.grid.major = element_line(color = "grey95", size = 0.2),
  panel.grid.minor = element_line(color = "grey95", size = 0.2),
  legend.key = element_blank(),
  legend.title = element_blank(),
  legend.spacing.x = unit(0.3, "cm"))

ggscat <- function(x = NA,
                   y,
                   fit = 'linear', # options: 'linear', 'smooth', NA
                   title = '',
                   ylab = '',
                   xlab = '',
                   R2 = TRUE,
                   equation = FALSE,
                   alpha = 0.4){
  require(ggplot2)
  theme_plot <- theme(
    legend.position = "bottom",
    panel.background = element_rect(fill = NA),
    panel.border = element_rect(fill = NA, color = "grey75"),
    axis.ticks = element_line(color = "grey85"),
    panel.grid.major = element_line(color = "grey95", size = 0.2),
    panel.grid.minor = element_line(color = "grey95", size = 0.2),
    legend.key = element_blank())

  if(length(x) == 1){
    if(is.na(x)){
      x = 1:length(y)
    }
  }

  df <- as.data.frame(x = x, y = y)

  if(R2 == TRUE){
    r2 <- paste("R2 =",round(summary(lm(y~x))$r.squared,3))
  } else{
    r2 <- ""
  }

  if(fit == 'smooth')
  {
    ggplot(df, aes(x, y)) + ggtitle(title) + ylab(ylab) + xlab(xlab) + geom_point(alpha = alpha, stroke = 0, size = 2) + ylim(min(y, na.rm = T), 1.05*max(y, na.rm = T)) + theme_plot + geom_smooth() + annotate("text", x = 0.9*max(x,na.rm = T), y = 1.05*max(y,na.rm=T), label = r2, colour="black", size = 4)
  } else if(fit == 'linear') {
    ggplot(df, aes(x, y)) + ggtitle(title) + ylab(ylab) + xlab(xlab) + geom_point(alpha = alpha, stroke = 0, size = 2) + ylim(min(y, na.rm = T), 1.05*max(y, na.rm = T)) + theme_plot + geom_smooth(method = 'lm') + annotate("text", x = 0.9*max(x,na.rm = T), y = 1.05*max(y,na.rm=T), label = r2, colour="black", size = 4)
  } else {
    ggplot(df, aes(x, y)) + ggtitle(title) + ylab(ylab) + xlab(xlab) + geom_point(alpha = alpha, stroke = 0, size = 2) + ylim(min(y, na.rm = T), 1.05*max(y, na.rm = T)) + theme_plot + annotate("text", x = 0.9*max(x,na.rm = T), y = 1.05*max(y,na.rm=T), label = r2, colour="black", size = 4)
  }
}
```

Import Data
```{r}
#setwd("~/Dropbox/Berkeley_tings/Fall 2018/ARE213/Problem Sets/SharedFiles/are213/PS1b")
#setwd("C:\\Users\\will-\\Desktop\\are213\\PS1b")
setwd("C:\\Users\\Will\\Desktop\\are213\\PS1b")
dat <- read.dta("ps1.dta")
#fix missing data
dat_drop <- dat %>% filter(herpes != 8 & tobacco != 9 & cigar != 99 & cigar6 != 6 & 
                  alcohol != 9 & drink != 99 & drink5 != 5 & wgain != 99)

dat_drop$tobacco_p <- ifelse(dat_drop$tobacco == 2, 0, dat_drop$tobacco)

#Linear Model for reference
dat.mod <- dat_drop %>% select(dbrwt,stresfip,dmage,ormoth,mrace3,dmeduc,dmar,adequacy,
               dtotord,monpre,nprevist,disllb,birmon,dgestat,csex,dplural,
               anemia,diabetes,herpes,chyper,pre4000,
               preterm,tobacco,cigar,alcohol,drink,wgain)

lm.mod <- lm(dbrwt ~., data = dat.mod)
```

# 1a - Misspecification bias

There are a number of possible sources for misspecification bias in our linear model estimates from PS1a.

One source of misspecification bias would be omitted variables bias.  The assumption that random assignment happens conditional on the observables does not protect us against non-random assignment of some unobservable covariate. Perhaps most importantly, however, is the likelihood that there exists some issue of endogeneity between the outcome variable and some of the control. For example, smoking while pregnant may contribute to hypertension, cardiac issues, or other factors that were considered in our initial model as control variables independent of the outcome variable.

A second source of misspecification bias would be in the functional form assumption of linearity. The control variables, including the treatment variable, are all assumed to have linear effects on the outcome variable, which may or may not be the correct functional form of the model, as some effects may in fact be non-linear, or there may exist important interaction effects between controls that were not considered.It could be the case that smoking has some non-linear effect on the birthweight of a baby that we would not capture in the linear model we estimated. We would want to explore nonparametric regression to evaluate the sensitivity to this misspecification.

# 1b - Higher order specifications

We explored using a series estimator of the following functional form:

```{r 1b}
dat_drop$dmage2 <- dat_drop$dmage^2
dat_drop$cigar2 <- dat_drop$cigar^2
dat_drop$cigar3 <- dat_drop$cigar^3
dat_drop$cig_dmag <- dat_drop$cigar*dat_drop$dmage

lm.out <- lm(dbrwt ~ stresfip+dmage+ormoth+mrace3+dmeduc+dmar+adequacy+dfage+
               orfath+dfeduc+dtotord+monpre+nprevist+disllb+birmon+dgestat+csex+dplural+
               anemia+diabetes+herpes+chyper+
               preterm+tobacco_p+cigar+alcohol+dmage2+cigar2+cigar3+cig_dmag, data = dat_drop)
summary(lm.out)

```


The benefits of this approach is that it potentially increases the accuracy of the prediction of treatment effect by removing misspecification bias. The drawbacks of this approach are the potential for overspecification, meaning the new specification is based more on the noise inherent in the data, and less on actual relationship of treatment to outcome. It will be hard to justify that all of the nonparametric decisions make intuitive economic or real world "sense". Finally, as you approach more parameters you could run into the curse of dimensionality when wanting to interpret a causal effect.

```{r }
## add nick's spline code
# Find knots based on equal quantiles of data
nknots <- 3
knots <- attr(bs(dat_drop$dbrwt, df = nknots+3), "knots") 
cspline.mod <- lm(dbrwt ~ bs(stresfip,knots = knots)+bs(dmage,knots = knots)+
                    bs(ormoth,knots = knots)+bs(mrace3,knots = knots)+
                    bs(dmeduc,knots = knots)+bs(dmar,knots = knots)+
                    bs(adequacy,knots = knots)+bs(dtotord,knots = knots)+
                    bs(monpre,knots = knots)+bs(nprevist,knots = knots)+
                    bs(disllb,knots = knots)+bs(birmon,knots = knots)+
                    bs(dgestat,knots = knots)+bs(csex,knots = knots)+
                    bs(dplural,knots = knots)+bs(anemia,knots = knots)+
                    bs(diabetes,knots = knots)+bs(herpes,knots = knots)+
                    bs(chyper,knots = knots)+bs(pre4000,knots = knots)+
                    bs(preterm,knots = knots)+bs(tobacco,knots = knots)+
                    bs(cigar,knots = knots)+bs(alcohol,knots = knots)+
                    bs(drink,knots = knots)+bs(wgain,knots = knots), 
                  data = dat_drop)
```

Here are graphs showing the predicted vs. observed birthweights using the simple linear model and with cubic splines.
```{r Compare Modeling Methods, echo=F}
ggscat(x = dat_drop$dbrwt, y = lm.mod$fitted.values, ylab = "Predicted Birthweight (grams)", xlab = "Observed Birthweight (grams)", title = "Predicted vs. Observed Birthweight - Linear Regression", fit = "linear", alpha = 0.3)

ggscat(x = dat_drop$dbrwt, y =cspline.mod$fitted.values, ylab = "Predicted Birthweight (grams)", xlab = "Observed Birthweight (grams)", title =  paste0("Predicted vs. Observed Birthweight - Cubic Spline (",nknots," equal quantile knots)"), fit = "smooth", alpha = 0.3) + geom_vline(xintercept = knots, linetype = "dashed", color = "grey80")
```

#1c - Using LASSO

In our application of lasso, we apply the method proposed by belloni, chernozhukov, and hansen. First we apply lasso on the treatment and the covariates.  Then, we apply it on the outcome variable and the covariates and keep the set of covariates that lasso selects in either 1 or 2. 

```{r 1c}
x_lasso <- dat_drop %>%
  select(stresfip,dmage,ormoth,mrace3,dmeduc,dmar,adequacy,dfage,
               orfath,dfeduc,dtotord,monpre,nprevist,disllb,birmon,dgestat,csex,dplural,
               anemia,diabetes,herpes,chyper,
               preterm,cigar,alcohol,dmage2,cigar2,cigar3,cig_dmag) %>% as.matrix()

y_lasso <- dat_drop %>% select(dbrwt) %>% as.matrix()

d_lasso <- dat_drop %>% select(tobacco_p) %>% as.matrix()

fit <- cv.glmnet(x_lasso,d_lasso)
coef(fit, s = "lambda.1se")

fit2 <- cv.glmnet(x_lasso,y_lasso)
coef(fit2, s = "lambda.1se")

```

Based on the estimates of 0 in both, we drop stresfip, adequacy, dfage, monpre, birmon, anemia, herpes, dfage2, dmage2, cigar2.

```{r 1c lasso}
lm.out <- lm(dbrwt ~ dmage+ormoth+mrace3+dmeduc+dmar+
               orfath+dfeduc+dtotord+nprevist+disllb+dgestat+csex+dplural+diabetes+chyper+
               preterm+tobacco_p+cigar+alcohol+cigar3+cig_dmag, data = dat_drop)
summary(lm.out)

```

Some of these terms I would have thought would have mattered such as adequacy of care and anemia.

#2 - Propensity score description

The propensity score helps solve the issue that it is hard to condition on the covariates if they are highly dimensional.  However, we want to do such conditioning in order to compare between treated and control units. The propensity score helps us proxy for the probability of entering treatment and therefore after conditioning on the propensity score, the units are as good as randomly assigned. 

#2a - Create propensity score

```{r}
Pcontrols = 'dmage+ ormoth+ mrace3+ dmeduc+ dmar+ dfage+ 
orfath+ dfeduc + disllb + isllb10 + anemia + diabetes+ herpes+ phyper'

# estimate propensity score
all_p <- glm( as.formula(paste( 'tobacco_p ~ ', Pcontrols)), 
                              dat_drop, family = binomial(logit))

summary(all_p)

dat_drop$p.hat_all <- predict(glm( as.formula(paste( 'tobacco_p ~ ', Pcontrols)), 
                              dat_drop, family = binomial(logit)), 
                         type = "response") # this is important!

Pcontrols2 = 'dmage+ ormoth+ mrace3+ dmeduc+ dmar+ 
dfage+ orfath+ dfeduc + disllb + isllb10 + phyper'

dat_drop$p.hat_2 <- predict(glm( as.formula(paste( 'tobacco_p ~ ', Pcontrols2)), 
                              dat_drop, family = binomial(logit)), 
                         type = "response") # this is important!

```

Anemia, diabetes, and herpes were all insignificant in the calculation of the propensity score.

```{r}
dat_drop$diff <- dat_drop$p.hat_all - dat_drop$p.hat_2

summary(dat_drop$diff)

```

The propensity scores were very comparable with at most a 5% difference and an average difference of 0%.

Further, we can see that excluding the non-significant covariates in the first propensity score estimation has a little overall effect on the propensity scores of being treated (R2 = 1).
```{r}
ggscat(dat_drop$p.hat_all,dat_drop$p.hat_2, xlab = "Prop. Scores w/ all Predetermined Vars", ylab = "Prop. Scores w/o Insignificant Predetermined Vars", title = "Propensity Score Comparison when Excluding Non-Significant Variables")
```
This implies that we have the right covariates that are predetermined in the problem from the original set of data but does not necessarily protect us against ommitted variables. 

#2b - propensity score estimation

```{r}
#Controlling for propensity scores
reg4 <- lm(dbrwt ~ tobacco_p + p.hat_2, data = dat_drop)
summary(reg4)
```

Using this approach, we estimate an average treatment effect of -231 grams as a result of smoking while pregnant. This treatment effect is consistent under unconfoundedness (i.e. random assignment of treatment conditional on the covariates) and the assumption of a constant (i.e., homogenous) treatment effect. Furthermore, it assumes that there is sufficient overlap of treatment and controls in the covariate space. 

#2c - propensity score reweighting

```{r}

ATE <- (sum(dat_drop$tobacco_p*dat_drop$dbrwt/dat_drop$p.hat_2)/
           sum(dat_drop$tobacco_p/dat_drop$p.hat_2)) - 
  (sum((1 - dat_drop$tobacco_p)*dat_drop$dbrwt/(1 - dat_drop$p.hat_2))/  
              sum((1 - dat_drop$tobacco_p) /(1 - dat_drop$p.hat_2)) )

print(ATE)


TOT <- ( sum(dat_drop$tobacco_p*dat_drop$dbrwt)/sum(dat_drop$tobacco_p)) - 
  sum(dat_drop$p.hat_2 *(1 - dat_drop$tobacco_p)*dat_drop$dbrwt / (1 - dat_drop$p.hat_2) ) / 
  sum(dat_drop$p.hat_2 * (1 - dat_drop$tobacco_p) /  
        (1 - dat_drop$p.hat_2))

print(TOT)
```



#2d kernel density estimator

Plotting the densities here for the full sample. The calculation of the kernel estimator at 3000g is shown under part e). 
```{r}
treatment <- density(dat_drop$dbrwt[dat_drop$tobacco_p==1], kernel = "gaussian", 
                     weights = dat_drop$p.hat_2[dat_drop$tobacco_p==1]/
                       sum(dat_drop$p.hat_2[dat_drop$tobacco_p==1]))

control <- density(dat_drop$dbrwt[dat_drop$tobacco_p==0], kernel = "gaussian", 
                   weights = (1 - dat_drop$p.hat_2[dat_drop$tobacco_p==0])/
                     sum((1 - dat_drop$p.hat_2[dat_drop$tobacco_p==0])))

plot(treatment,
lty = 'dashed',
main = "",
xlab = "Birthweight in grams",
ylab = "Density")
lines(control)
legend(x = 'topleft', legend = c('Everyone Smoker', 'Everyone Non-Smoker'),
lty = c('dashed', 'solid'), bty = "n")

```

#2e - kernel density bandwidth adjustments
```{r, fig.height=10}
n <- nrow(dat_drop)
y <- dat_drop$dbrwt
D <- dat_drop$tobacco_p
#Number of Control Obs
nC <- length(D[D==0])
nT <- length(D[D==1])
par(mfrow = c(3,2))
for(adj in c(0.1,0.25,0.5,1,2,10)){
# Define Bandwidth
h0 <- density(y)$bw
bw_adjust <- adj
h <- h0*bw_adjust

# Control & Treatment Densities
Cdens <- density(y[D==0], adjust = bw_adjust)
Tdens <- density(y[D==1], adjust = bw_adjust)

#Plot densities
plot(Cdens, col = "blue", main = paste0("Bandwidth = ",round(h,2),"g"), xlab = "grams")
lines(Tdens, col = "red")
legend('topright', legend = c("Control", "Treated"), col = c("blue", "red"), lty = 1)
}
```

In the above figure, we could see that with smaller bandwidths, the kernal densities get much more jagged, or variable. However, as we increase the bandwidth and the curves become smoother, it's also evident that there is more bias in the estimates because the magnitudes of the curves begin to change relative to one another (i.e. the peak of the control curve starts to decline as the bandwidth is increased).

The default bandwidth of ~44 grams seems to produce a fairly smooth kernal density, and was selected as the preferred bandwidth.
```{r}
h0 <- density(y)$bw
bw_adjust <- 1
h <- h0*bw_adjust

# Control & Treatment Densities
Cdens <- density(y[D==0], adjust = bw_adjust)
Tdens <- density(y[D==1], adjust = bw_adjust)

#Plot densities
plot(Cdens, col = "blue", main = paste0("Kernal Densities of Birthweight (Bandwidth = ",
                                        round(h,2),"g)"), xlab = "grams")
lines(Tdens, col = "red")
legend('topright', legend = c("Control", "Treated"), col = c("blue", "red"), lty = 1)
```

Solving for kernel estimator at birthweight = 3000 grams.
```{r}
# Uniform kernal function
k.uni <- function(u){
  return(ifelse(abs(u) <= 1,0.5,0))
}

# Triangular kernal function
k.tri <- function(u){
  return(ifelse(abs(u) < 1,1-abs(u),0))
}

# Epanechnikov kernal function
k.epan <- function(u){
  return(ifelse(abs(u) < 1,0.75*(1-u^2),0))
}

# Gaussian kernal function
k.gauss <- function(u){
  return((1/sqrt(2*pi))*exp(-0.5*u^2))
}

# Kernal Density Estimator for Control Group
k.dens.C <- function(ystar, k.func){
  ks <- rep(NA,nC)
  for(i in 1:n){
    u <- (ystar - y[i])/h
    ks[i] <- k.func(u)*(1-D[i])/(1-dat_drop$p.hat_2[i])
  }
  return((1/(nC*h))*(sum(ks)))
}

# Kernal Density Estimator for Treatment Group
k.dens.T <- function(ystar, k.func){
  ks <- rep(NA,nT)
  for(i in 1:n){
    u <- (ystar - y[i])/h
    ks[i] <- k.func(u)*(D[i]/dat_drop$p.hat_2[i])
  }
  return((1/(nT*h))*(sum(ks)))
}
```
Kernal Estimates at 3000g
```{r}
h <- density(y)$bw

est.uni.C <- k.dens.C(3000,k.func = k.uni) %>% round(6)
est.tri.C <- k.dens.C(3000,k.func = k.tri) %>% round(6)
est.epan.C <- k.dens.C(3000,k.func = k.epan) %>% round(6)
est.gauss.C <- k.dens.C(3000,k.func = k.gauss) %>% round(6)

est.uni.T <- k.dens.T(3000,k.func = k.uni) %>% round(6)
est.tri.T <- k.dens.T(3000,k.func = k.tri) %>% round(6)
est.epan.T <- k.dens.T(3000,k.func = k.epan) %>% round(6)
est.gauss.T <- k.dens.T(3000,k.func = k.gauss) %>% round(6)

est.df <- data.frame(Kernal = c("Uniform","Triangular","Epanechnikov","Gaussian"), 
                     NonSmoker = c(est.uni.C,est.tri.C,est.epan.C,est.gauss.C),Smoker = c(est.uni.T,est.tri.T,est.epan.T,est.gauss.T))
kable(est.df, caption = "Kernal Estimates for Birthweight of 3000g")
```

We can see that as expected, the point kernal estimates for the smoker (treated) at 3000g are higher relative to non-smokers (control), which is inline with what the kernal density functions demonstrate above.  Therefore, this can be interpreted, that on average, being a smoker means your overall likelihood of having a child of exactly 3000g is higher than being a non-smoker. 3000g, while not considered especially low, is below average for both the control and treated birthweight distributions seen above.

#2f - benefits and drawbacks of propensity method

The benefits of the propensity weighting approach in part c is that it allows for conditioning solely on the likelihood of selecting into treatment, rather than on all predetermined control variables, which rectifies issues that arise when matching across many variables (Curse of Dimensionality).

Furthermore, we know that propensity scores are not balanced across treated and control groups. The weighting scheme ensures that each observation is equally represented (in expectation) in the treated and control groups.  According to to Hirano, Imbens,and Ridder, the weighting estimator we use is efficient. However, very low and very high propensity scores may weight observations to 0 or infinity and bias the results. 

#2g - Present and discuss results

i. Must hold. The inverse weighting of propensity scores seems more reasonable if the treatment effect heterogeneity is linear in the propensity scores. If it is non-linear we might need to use a differenet weighting mechanism. 

ii. Need not hold. If it is non-linear we might need to use a differenet weighting mechanism. Our weighhting mechanism in 2c might not be accurate. 

iii. Need not hold.  Without conditioning for propensity scores we saw a systemic difference between smokers and non smokers who selected into treatment. The systematic dfference was accounted for when we calclated the propensity scores.  

iv. Must hold. On taking propensity scores, we account for the exogenous variation and the decision to smoke is as good as randomly assigned. If conditional  on  the  exogenous  variables  the  decision  to  smoke  is still not randomly assigned we will get biased estimnates for ATE and TOT. 


#3 - Blocking non-parametric approach

```{r}

# Create 100 equally sized bins based on propensity scores 

dat_drop$bin <- cut(dat_drop$p.hat_2, breaks = seq(0,1,0.01), 
                    include.lowest = TRUE, labels = FALSE)

# Find difference between birth weights of non-smokers and smokers in each bin, 
#and assign weights to them. The final treatment effect is then calculated by 
#summing the individual weighted mean differences

treatment_effect = 0

treatments <- c()
for(i in 1:100)
{
  
mean_diff = mean(dat_drop$dbrwt[dat_drop$tobacco_p==1 & dat_drop$bin==i]) -
  mean(dat_drop$dbrwt[dat_drop$tobacco_p==0 & dat_drop$bin==i]) 
treatments <- c(treatments, mean_diff)
#print(i)
#print(mean_diff)

N <- nrow(dat_drop)
N1 <- nrow(dat_drop[dat_drop$tobacco_p==1 & dat_drop$bin == i,])
N0 <- nrow(dat_drop[dat_drop$tobacco_p==0 & dat_drop$bin == i,])

weighted_mean <- mean_diff*((N1+N0)/N)
#print(weighted_mean)
if(is.nan(weighted_mean)){
  final_mean = 0 } else
    {
    
   final_mean = weighted_mean
  }


treatment_effect = final_mean + treatment_effect
}

print(treatment_effect)
plot(treatments)
```

The result from this weighted mean difference method shows that on average, babies of smokers have lower birth weights by 233.3 grams as compared to babies of non-smokers.This is almost equal to the ATE of -232 grams found in the previous question where we did not block as per propensity scores. These equal results show that there are no systematic differences between smokers and non-smokers based on the other covariates included in the study. 


A plot of all of the mean treatment effects in each bin shows a pretty stable line for each bin except at the extremes where there are limited p scores available.

#4 - low birth weights

```{r}
# Create a low birth weight indicator variable
dat_drop$low <- 0
dat_drop$low[dat_drop$dbrwt < 2500] <- 1 

# Find difference between proportion of low birth weights between non-smokers and smokers in each bin, 
#and then weight them as per blocking method described in class. The final treatment effect is then 
#calculated by summing the individual weighted mean differences

treatment_effect = 0
treatments <- c()

for(i in 1:100)
{
  
mean_diff = mean(dat_drop$low[dat_drop$tobacco_p==1 & dat_drop$bin==i]) - 
  mean(dat_drop$low[dat_drop$tobacco_p==0 & dat_drop$bin==i])
treatments <- c(treatments, mean_diff)
#print(i)
#print(mean_diff)

N <- nrow(dat_drop)
N1 <- nrow(dat_drop[dat_drop$tobacco_p==1 & dat_drop$bin == i,])
N0 <- nrow(dat_drop[dat_drop$tobacco_p==0 & dat_drop$bin == i,])

weighted_mean <- mean_diff*((N1+N0)/N)
#print(weighted_mean)
if(is.nan(weighted_mean)){
  final_mean = 0 } else
    {
    
   final_mean = weighted_mean
  }


treatment_effect = final_mean + treatment_effect

}

print(treatment_effect)

# Difference in proportion of low birthweight babies between smokers and non-smokers
low_diff <- (nrow(dat_drop[dat_drop$low ==1 & dat_drop$tobacco_p==1,])/
               nrow(dat_drop[dat_drop$tobacco_p==1,]) - nrow(dat_drop[dat_drop$low ==1 &                                                              dat_drop$tobacco_p==0,])/nrow(dat_drop[dat_drop$tobacco_p==0,]))

low_diff
```

The result shows that smokers have a 4.448 pc higher proportion of low birthweight babies than do non-smokers. This is almost equal to the absolute difference of 4.515 pc in the proportion of low birth weight babies between smokers and non-smokers. Hence, we can say that there are no systematic differences in birth weights between the bins/blocks created, indicating that we have a uniform distribution of data across the bins.

#5 - Summarize results

Drawing on our results from the previous assignment where we found that birth weights of smokers were on average 231.8 gms lower than the birth weights of non-smokers, we now allow the relationship between birth weight and the explanatory variables to assume a non-linear functional form. In order to ensure that the selection into treatment does not differ in some meaningful way from the units that do not select into treatment, we condition the regression on propensity scores. The propensity scores are calculated using all the pre-determined covariates and quadratic terms for age of mother and father, based on observation of the functional form and results of the LASSO regression estimate. The results show that the average treatment effect of smoking increased to 234 gms on controlling for the propensity scores, showing that some of the difference in birth weights between smokers and non-smokers was due to systematic differences in how smokers selected into the treatment. 
In order to balance the propensity scores across treatment and control groups, we use a weighting method which ensures that smokers and non-smokers are equally represented across both groups. The results for this regression show that the ATE is 232 gms which is the same as our previous result from the conditional regression. However, the treatment on treated effect is found to be 229 gms showing that the difference in birth weights is lower for those who actually selected into treatment and control versus those who had the highest likelihood of being in either group. 
We also use a blocking method based on propensity scores to confirm that there are no block-wise differences between smokers and non-smokers with similar propensity scores. The results indicate an ATE of 234.3 gms which is almost equal to the ATE found previously, showing that there are no systematic differences between smokers and non-smokers based on the other covariates included in the study. Using the blocking method, we also find that smokers have a 4.45 pc higher proportion of low birthweight babies than do non-smokers.

